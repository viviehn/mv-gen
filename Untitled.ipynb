{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "import tensorflow as tf\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = tf.TFRecordReader()\n",
    "def Dequantize(feat_vector, max_quantized_value=2, min_quantized_value=-2):\n",
    "  \"\"\"Dequantize the feature from the byte format to the float format.\n",
    "\n",
    "  Args:\n",
    "    feat_vector: the input 1-d vector.\n",
    "    max_quantized_value: the maximum of the quantized value.\n",
    "    min_quantized_value: the minimum of the quantized value.\n",
    "\n",
    "  Returns:\n",
    "    A float vector which has the same shape as feat_vector.\n",
    "  \"\"\"\n",
    "  assert max_quantized_value > min_quantized_value\n",
    "  quantized_range = max_quantized_value - min_quantized_value\n",
    "  scalar = quantized_range / 255.0\n",
    "  bias = (quantized_range / 512.0) + min_quantized_value\n",
    "  return feat_vector * scalar + bias\n",
    "\n",
    "def decode(feat_vector, feature_size):\n",
    "    return tf.reshape(tf.cast(tf.decode_raw(feat_vector, \n",
    "                                            tf.uint8), \n",
    "                              tf.float32),\n",
    "                      [-1, feature_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read and print data:\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "# Read TFRecord file\n",
    "reader = tf.TFRecordReader()\n",
    "filename_queue = tf.train.string_input_producer(['output.tfrecord'])\n",
    "\n",
    "_, serialized_example = reader.read(filename_queue)\n",
    "\n",
    "# Define context\n",
    "context = {\n",
    "    'id': tf.FixedLenFeature([], dtype=tf.string),\n",
    "    'labels': tf.VarLenFeature(dtype=tf.int64)\n",
    "}\n",
    "\n",
    "feature_list = {\n",
    "    'rgb': tf.FixedLenSequenceFeature([], dtype=tf.string),\n",
    "    'audio': tf.FixedLenSequenceFeature([], dtype=tf.string)\n",
    "}\n",
    "\n",
    "\n",
    "# Extract features from serialized data\n",
    "\n",
    "\n",
    "context, features = tf.io.parse_single_sequence_example(serialized_example,\n",
    "                                                context_features=context,\n",
    "                                                sequence_features=feature_list,\n",
    "                                                example_name=None,\n",
    "                                                name=None\n",
    ")\n",
    "\n",
    "# Many tf.train functions use tf.train.QueueRunner,\n",
    "# so we need to start it before we read\n",
    "tf.train.start_queue_runners(sess)\n",
    "feature_names = ['audio', 'rgb']\n",
    "sizes = [128, 1024]\n",
    "# Print features\n",
    "#for i in range(len(feature_names)):\n",
    "    \n",
    "   #print('{}: {}'.format(feature_names[i], Dequantize(decode(features[feature_names[i]], sizes[i])).eval()))\n",
    "   #print('\\n')\n",
    "    \n",
    "audio = Dequantize(decode(features['audio'],128)).eval()\n",
    "rgb = Dequantize(decode(features['rgb'],1024)).eval()\n",
    "\n",
    "tf.InteractiveSession().close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(205, 128)\n",
      "(197, 1024)\n",
      "Context:\n",
      "labels: SparseTensorValue(indices=array([[0]]), values=array([14]), dense_shape=array([1]))\n",
      "id: b'/Users/viviehn/Classwork/cs182/final/New EDM Beats/093.mp4'\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[[-1.9921875  -0.8627757   0.73722434 ...  0.23526359 -0.1255207\n",
      "   0.17251849]\n",
      " [ 0.658793   -0.03140306  0.8627145  ...  0.8627145   0.12545967\n",
      "   1.2078128 ]\n",
      " [ 0.5803616  -0.09414816  0.61173415 ... -1.0666972   1.0195775\n",
      "   0.42349887]\n",
      " ...\n",
      " [-1.9921875  -1.3804228   0.36075377 ... -0.53336394  1.0980089\n",
      "  -0.14120698]\n",
      " [-1.9921875  -1.3647366   0.3450675  ... -0.5490502   1.003891\n",
      "  -0.29806972]\n",
      " [-1.9921875  -1.3647366   0.3450675  ... -0.53336394  0.9882047\n",
      "  -0.313756  ]]\n"
     ]
    }
   ],
   "source": [
    "audio = decode(features['audio'],128).eval()\n",
    "rgb = Dequantize(decode(features['rgb'],1024)).eval()\n",
    "print(audio.shape)\n",
    "print(rgb.shape)\n",
    "print('Context:')\n",
    "for name, tensor in context.items():\n",
    "    print('{}: {}'.format(name, tensor.eval()))\n",
    "print(audio[50:100, 50:100])\n",
    "print(rgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'YT8MFrameFeatureReader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-66-347bf5ba19c6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mreader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mYT8MFrameFeatureReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mfilename_queue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_input_producer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'output.tfrecord'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_reader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename_queue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'YT8MFrameFeatureReader' is not defined"
     ]
    }
   ],
   "source": [
    "reader = YT8MFrameFeatureReader()\n",
    "filename_queue = tf.train.string_input_producer(['output.tfrecord'])\n",
    "reader.prepare_reader(filename_queue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
